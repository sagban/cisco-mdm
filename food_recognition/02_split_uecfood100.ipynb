{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_split_uecfood100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split UECFOOD256 dataset to training, val, testing sets with ratio 0.7, 0.2, 0.1\n",
    "- Save img_dir, category_id, x1, y1, x2, y2 into txt file under train_uec256.txt, val_uec256.txt and test_uec256.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset():\n",
    "    dataset_disk = os.path.join(os.getcwd(), \"Dataset\")\n",
    "#     uecfood100_path = dataset_disk + 'UECFOOD100_448'\n",
    "    datapath = dataset_disk\n",
    "    category = 'category.txt'\n",
    "    bbox_info = 'bb_info.txt'\n",
    "\n",
    "    split = [0.8, 0.1, 0.1]\n",
    "    files_generated = ['train_food.txt', 'val_food.txt', 'test_food.txt']\n",
    "\n",
    "    # Put first column (id) and second column (name) from category.txt into two lists\n",
    "    category_ids = []\n",
    "    category_names = []\n",
    "    with open(os.path.join(datapath, category), 'r') as category_list:\n",
    "        for i, line in enumerate(category_list):\n",
    "            if i >= 0:\n",
    "                line = line.rstrip('\\n')  # delete \\n in the end of th\n",
    "                # e line\n",
    "                line = line.split(' ')\n",
    "                category_ids.append(int(line[0]))\n",
    "                category_names.append(line[1])\n",
    "\n",
    "    print(category_names)\n",
    "    # Read bb_info.txt based on category id\n",
    "    category_images = []\n",
    "    category_bbox = []\n",
    "    for id_index, id in enumerate(category_ids):\n",
    "        category_images.append([])\n",
    "        category_bbox.append([])\n",
    "        with open(os.path.join(datapath ,str(id), bbox_info), 'r') as bbox_list:\n",
    "            for i, line in enumerate(bbox_list):\n",
    "                if i > 0:\n",
    "                    line = line.rstrip('\\n')\n",
    "                    line = line.split(' ')\n",
    "                    category_images[id_index].append(line[0])\n",
    "                    category_bbox[id_index].append(list(map(float, line[1:])))\n",
    "\n",
    "    # Split categories to train/val/test with ratio define before\n",
    "    train_food = []\n",
    "    val_food = []\n",
    "    test_food = []\n",
    "    for id_index, id in enumerate(category_ids):\n",
    "        # divide each category with 70% training, 20% val, 10% testing\n",
    "        n_imgs = len(category_images[id_index])\n",
    "        n_train = int(np.floor(n_imgs * split[0]))\n",
    "        n_val = int(np.floor(n_imgs * split[1]))\n",
    "        n_test = int(n_imgs - n_train - n_val)\n",
    "        print(\"For caterogy: {}\".format(category_names[id_index]))\n",
    "        print(\"n_train: {} n_val: {} n_test: {}\".format(n_train, n_val, n_test))\n",
    "        # shuffle images\n",
    "        shuffled_imgs = random.sample(category_images[id_index], n_imgs)\n",
    "\n",
    "        train_food.append(shuffled_imgs[:n_train])  # not including the last one\n",
    "        val_food.append(shuffled_imgs[n_train:n_train + n_val])\n",
    "        test_food.append(shuffled_imgs[n_train + n_val:])\n",
    "\n",
    "    all_train_list = list(np.unique(list(itertools.chain(*train_food))))\n",
    "    all_val_list = list(np.unique(list(itertools.chain(*val_food))))\n",
    "    all_test_list = list(np.unique(list(itertools.chain(*test_food))))\n",
    "    all_list = [all_train_list, all_val_list, all_test_list]\n",
    "\n",
    "    # Pop out element in training set if it's in testing or val also\n",
    "    i = 0\n",
    "    while i < len(all_train_list):  # give priority to val and test over train\n",
    "        if all_train_list[i] in all_val_list:  # training sample is in val set too\n",
    "            all_train_list.pop(i)\n",
    "        elif all_train_list[i] in all_test_list:  # training sample is in test set too\n",
    "            all_train_list.pop(i)\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # Pop out element in testing set if it's in val also\n",
    "    i = 0\n",
    "    while i < len(all_test_list):  # give priority to val over test\n",
    "        if all_test_list[i] in all_val_list:  # test sample is in val set too\n",
    "            all_test_list.pop(i)\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # Split bounding box with train, val, test sets\n",
    "    imgs_format = 'jpg'\n",
    "    file = open(os.path.join(datapath, \"classes.txt\"), 'w')\n",
    "    for c in category_names:\n",
    "        file.write(c + '\\n')\n",
    "    file.close()\n",
    "\n",
    "    \n",
    "    for i, all_list_item in enumerate(all_list):\n",
    "        \n",
    "        file = open(os.path.join(datapath, files_generated[i]), 'w')\n",
    "        file.write('img category_id x1 y1 x2 y2\\n')  # header\n",
    "        for img in all_list_item:\n",
    "            # it is possible that one image in several categories\n",
    "            occurrences = []\n",
    "            for id_index, id in enumerate(category_ids):\n",
    "                occ = [[os.path.join(datapath, str(id), img + '.' + imgs_format), str(id)] +\n",
    "                       category_bbox[id_index][i] for i, elem in enumerate(category_images[id_index]) if elem == img]\n",
    "                occurrences += occ\n",
    "\n",
    "            for occ in occurrences:\n",
    "                img_path = occ[0]\n",
    "                img_category = occ[1]\n",
    "                img_bbox = str(occ[2]) + ' ' + str(occ[3]) + ' ' + str(occ[4]) + ' ' + str(occ[5])\n",
    "                file.write(img_path + ' ' + img_category + ' ' + img_bbox + '\\n')\n",
    "        file.close()\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rice', 'roti', 'dal', 'sabzi']\n",
      "For caterogy: rice\n",
      "n_train: 732 n_val: 91 n_test: 92\n",
      "For caterogy: roti\n",
      "n_train: 308 n_val: 38 n_test: 39\n",
      "For caterogy: dal\n",
      "n_train: 373 n_val: 46 n_test: 48\n",
      "For caterogy: sabzi\n",
      "n_train: 705 n_val: 88 n_test: 89\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "split_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The generated txt file should like this: **   \n",
    "/Volumes/JS/UECFOOD100_JS/1/10.jpg 1 81.0 20.0 546.0 421.0  \n",
    "/Volumes/JS/UECFOOD100_JS/2/100.jpg 2 58.0 0.0 748.0 582.0  \n",
    "/Volumes/JS/UECFOOD100_JS/11/1000.jpg 11 28.0 17.0 611.0 594.0  \n",
    "/Volumes/JS/UECFOOD100_JS/11/1001.jpg 11 54.0 38.0 667.0 573.0  \n",
    "/Volumes/JS/UECFOOD100_JS/11/1003.jpg 11 0.0 0.0 800.0 600.0    \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
